{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09aca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.14.tar.gz (82 kB)\n",
      "     ---------------------------------------- 0.0/82.1 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 10.2/82.1 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 30.7/82.1 kB 325.1 kB/s eta 0:00:01\n",
      "     -------------- ----------------------- 30.7/82.1 kB 325.1 kB/s eta 0:00:01\n",
      "     ---------------------------- --------- 61.4/82.1 kB 326.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 82.1/82.1 kB 352.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.6.14-py3-none-any.whl size=105134 sha256=2e69759dc2e246da84ce8da4c042be00181ca43afba542c4ad52dab0ea2e0868\n",
      "  Stored in directory: c:\\users\\alberreal\\appdata\\local\\pip\\cache\\wheels\\ec\\d9\\04\\93be57edf3835182a8e76d8ff87f7e77a0113f473ba3721ee0\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.6.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script kaggle.exe is installed in 'C:\\Users\\AlberReal\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488660ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52536328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the desired size (e.g., 224x224 for ResNet)\n",
    "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet values\n",
    "    transforms.Normalize(mean=[0.4581, 0.4581, 0.4581], std=[0.2589, 0.2589, 0.2589])  # Values for this dataset\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae395229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = ImageFolder(root='mini child dataset', transform=transform)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e63937e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 10\n",
       "    Root location: mini child dataset\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.4581, 0.4581, 0.4581], std=[0.2589, 0.2589, 0.2589])\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding mean and std for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root='mini child dataset', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "n_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in dataloader:\n",
    "    # Resize images to [N, 3, H, W]\n",
    "    images = images.view(images.size(0), images.size(1), -1)\n",
    "    # Update the sum and sum of squares\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    n_samples += images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ac477",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean /= n_samples\n",
    "std /= n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d77a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of finding mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd157e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_ds, valid_ds = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018919eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(train_ds)[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776d0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(valid_ds, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1532a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 10\n",
      "Training images: 8\n",
      "Testing images: 2\n"
     ]
    }
   ],
   "source": [
    "# Verify the dataset structure and labels\n",
    "print(f'Total images: {len(dataset)}')\n",
    "print(f'Training images: {len(train_ds)}')\n",
    "print(f'Testing images: {len(valid_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2ddf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # Batch size x Channels x Height x Width\n",
    "    print(labels)        # Labels for the batch\n",
    "    break  # Just checking one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb59cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e64c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e417fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from dataset import *\n",
    "from model import ResNet18\n",
    "from unlearn import *\n",
    "from metrics import UnLearningScore\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e606b811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "#train_ds = CustomCIFAR100(root='.', train=True,download=True, transform=transform_train)\n",
    "#valid_ds = CustomCIFAR100(root='.', train=False,download=True, transform=transform_train)\n",
    "\n",
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d8927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"num_classes = 100\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label, clabel in train_ds:\n",
    "    classwise_train[label].append((img, label, clabel))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label, clabel in valid_ds:\n",
    "    classwise_test[label].append((img, label, clabel))\"\"\"\n",
    "    \n",
    "num_classes = 2\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97228e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00100, train_loss: 0.7966, val_loss: 0.8231, val_acc: 50.0000\n",
      "Epoch [1], last_lr: 0.00100, train_loss: 0.0268, val_loss: 1.2741, val_acc: 50.0000\n",
      "Epoch [2], last_lr: 0.00100, train_loss: 0.0190, val_loss: 2.1944, val_acc: 50.0000\n",
      "Epoch [3], last_lr: 0.00100, train_loss: 0.0011, val_loss: 3.0285, val_acc: 50.0000\n",
      "Epoch [4], last_lr: 0.00100, train_loss: 0.0002, val_loss: 3.9321, val_acc: 50.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "#device = 'cuda'\n",
    "device = 'cpu'\n",
    "                                                                                                                                                                                                                               \n",
    "epochs = 5\n",
    "history = fit_one_cycle(epochs, model, train_dl, valid_dl, device = device)\n",
    "torch.save(model.state_dict(), \"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f162fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b694e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained model\n",
    "#device = 'cuda'\n",
    "model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
    "model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21037453",
   "metadata": {},
   "source": [
    "# Forgetting Rocket\n",
    "The Rocket is class 69 in CIFAR100 and belongs to Super Class 19 (Vehicles) in CIFAR Super 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b58c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the forget and retain validation data\n",
    "\"\"\"forget_valid = []\n",
    "forget_classes = [0]\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label, clabel in classwise_test[cls]:\n",
    "            forget_valid.append((img, label, clabel))\n",
    "\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label, clabel in classwise_test[cls]:\n",
    "            retain_valid.append((img, label, clabel))\n",
    "            \n",
    "forget_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            forget_train.append((img, label, clabel))\n",
    "\n",
    "retain_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            retain_train.append((img, label, clabel))\"\"\"\n",
    "forget_valid = []\n",
    "forget_classes = [0]\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "            \n",
    "forget_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label in classwise_train[cls]:\n",
    "            forget_train.append((img, label))\n",
    "\n",
    "retain_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label in classwise_train[cls]:\n",
    "            retain_train.append((img, label))\n",
    "\n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=32, pin_memory=True)\n",
    "\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=32, pin_memory=True)\n",
    "\n",
    "forget_train_dl = DataLoader(forget_train, batch_size, num_workers=32, pin_memory=True)\n",
    "retain_train_dl = DataLoader(retain_train, batch_size, num_workers=32, pin_memory=True, shuffle = True)\n",
    "import random\n",
    "retain_train_subset = random.sample(retain_train, int(0.3*len(retain_train)))\n",
    "retain_train_subset_dl = DataLoader(retain_train_subset, batch_size, num_workers=32, pin_memory=True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03937bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Fully trained model on retain set\n",
    "evaluate(model, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Fully trained model on retain set\n",
    "evaluate(model, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511d908",
   "metadata": {},
   "source": [
    "## Retrain the model from Scratch\n",
    "Create Retrained Model (Gold model). This is the model trained from scratch without forget data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "gold_model = ResNet18(num_classes = 20, pretrained = True).to(device)\n",
    "epochs = 5\n",
    "history = fit_one_cycle(epochs, gold_model, retain_train_dl, retain_valid_dl, device = device)\n",
    "torch.save(gold_model.state_dict(), \"ResNET18_CIFAR100Super20_Pretrained_Gold_Class69_5_Epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "gold_model = ResNet18(num_classes = 20, pretrained = True).to(device)\n",
    "gold_model.load_state_dict(torch.load(\"ResNET18_CIFAR100Super20_Pretrained_Gold_Class69_5_Epochs.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate gold model on forget set\n",
    "evaluate(gold_model, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9deb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate gold model on retain set\n",
    "evaluate(gold_model, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52614d",
   "metadata": {},
   "source": [
    "## UnLearning via proposed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "unlearning_teacher = ResNet18(num_classes = 20, pretrained = False).to(device).eval()\n",
    "student_model = ResNet18(num_classes = 20, pretrained = False).to(device)\n",
    "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))\n",
    "model = model.eval()\n",
    "\n",
    "KL_temperature = 1\n",
    "\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr = 0.0001)\n",
    "\n",
    "blindspot_unlearner(model = student_model, unlearning_teacher = unlearning_teacher, full_trained_teacher = model, \n",
    "          retain_data = retain_train_subset, forget_data = forget_train, epochs = 1, optimizer = optimizer, lr = 0.0001, \n",
    "          batch_size = 256, num_workers = 32, device = device, KL_temperature = KL_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdd978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of unlearned model on forget set\n",
    "evaluate(student_model, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10464482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance of unlearned model on retain set\n",
    "evaluate(student_model, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22adfc9",
   "metadata": {},
   "source": [
    "### Measure ZRF (Unlearning Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5293709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial Score: {}\".format(UnLearningScore(model, unlearning_teacher, forget_valid_dl, 256, 'cuda')))\n",
    "print(\"Our Score: {}\".format(UnLearningScore(student_model, unlearning_teacher, forget_valid_dl, 256, 'cuda')))\n",
    "print(\"Gold Score: {}\".format(UnLearningScore(gold_model, unlearning_teacher, forget_valid_dl, 256, 'cuda')))\n",
    "print(\"JS Div: {}\".format(1-UnLearningScore(gold_model, student_model, forget_valid_dl, 256, 'cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abfa01",
   "metadata": {},
   "source": [
    "## Unlearning using Amnesiac unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearninglabels = list(range(20))\n",
    "unlearninglabels.remove(19)\n",
    "unlearning_train_set = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            unlearning_train_set.append((img, label, random.choice(unlearninglabels)))\n",
    "\n",
    "\n",
    "\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            unlearning_train_set.append((img, label, clabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearning_train_set_dl = DataLoader(unlearning_train_set, batch_size, num_workers = 32, pin_memory = True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "student_model = ResNet18(num_classes = 20, pretrained = True).to(device)\n",
    "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = 'cuda'))\n",
    "epochs = 3\n",
    "\n",
    "history = fit_one_unlearning_cycle(epochs, student_model, unlearning_train_set_dl, retain_valid_dl, device = device, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47012a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
    "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfcfd6",
   "metadata": {},
   "source": [
    "## Unlearning using UNSIR (Class 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13dc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 20\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label, clabel in train_ds:\n",
    "    classwise_train[clabel].append((img, label, clabel))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label, clabel in valid_ds:\n",
    "    classwise_test[clabel].append((img, label, clabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the forget and retain validation data\n",
    "forget_valid = []\n",
    "forget_classes = [0]\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label, clabel in classwise_test[cls]:\n",
    "            forget_valid.append((img, label, clabel))\n",
    "\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label, clabel in classwise_test[cls]:\n",
    "            retain_valid.append((img, label, clabel))\n",
    "            \n",
    "forget_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            forget_train.append((img, label, clabel))\n",
    "\n",
    "retain_train = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in forget_classes:\n",
    "        for img, label, clabel in classwise_train[cls]:\n",
    "            retain_train.append((img, label, clabel))\n",
    "\n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=32, pin_memory=True)\n",
    "\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=32, pin_memory=True)\n",
    "\n",
    "forget_train_dl = DataLoader(forget_train, batch_size, num_workers=32, pin_memory=True)\n",
    "retain_train_dl = DataLoader(retain_train, batch_size, num_workers=32, pin_memory=True, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect some samples from each class\n",
    "num_samples = 500\n",
    "retain_samples = []\n",
    "for i in range(num_classes):\n",
    "    if i not in forget_classes:\n",
    "        retain_samples += classwise_train[i][:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07307a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "student_model = ResNet18(num_classes = 20, pretrained = False).to(device)\n",
    "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035388b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = UNSIR_noise(batch_size, 3, 224, 224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_class_label = 0\n",
    "num_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise =  UNSIR_noise_train(noise, student_model, forget_class_label, num_epochs,\\\n",
    "                           noise_batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6babe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_loader = UNSIR_create_noisy_loader(noise, forget_class_label\\\n",
    "                                         , retain_samples, batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7942492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impair step\n",
    "epochs = 1\n",
    "history = fit_one_unlearning_cycle(epochs, student_model, noisy_loader, retain_valid_dl, device = device, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ba1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
    "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa107882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repair step\n",
    "other_samples = []\n",
    "for i in range(len(retain_samples)):\n",
    "    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][2]),\n",
    "                            torch.tensor(retain_samples[i][2])))    \n",
    "\n",
    "heal_loader = torch.utils.data.DataLoader(other_samples, batch_size=batch_size, shuffle = True)\n",
    "epochs = 1\n",
    "history = fit_one_unlearning_cycle(epochs, student_model, heal_loader, retain_valid_dl, device = device, lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
    "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118f1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
