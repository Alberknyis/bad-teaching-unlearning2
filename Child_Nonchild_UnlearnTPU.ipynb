{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision\n",
        "!pip install torch==2.2.0 torchvision==0.17.0\n",
        "!pip uninstall tensorflow\n",
        "!pip uninstall jax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lNvW-ivQ0_l",
        "outputId": "38817162-fd71-4bfb-9a1b-4cc3f7e11102"
      },
      "id": "0lNvW-ivQ0_l",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.3.0+cu121\n",
            "Uninstalling torch-2.3.0+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.3.0+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-2.3.0+cu121\n",
            "Found existing installation: torchvision 0.18.0+cu121\n",
            "Uninstalling torchvision-0.18.0+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision-0.18.0+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libcudart.7ec1eba6.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libnvjpeg.f00ca762.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libz.4100288c.so.1\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torchvision-0.18.0+cu121\n",
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.17.0\n",
            "  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.0) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.0) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.17.0) (9.4.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.17.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.17.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.17.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.17.0) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchvision-0.17.0 triton-2.2.0\n",
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.15.0\n",
            "Found existing installation: jax 0.4.26\n",
            "Uninstalling jax-0.4.26:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/jax-0.4.26.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/jax/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled jax-0.4.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opT7nDtpH_09"
      },
      "id": "opT7nDtpH_09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Alberknyis/bad-teaching-unlearning2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNNDIP5AR58A",
        "outputId": "59e47263-d1b1-4248-fa8f-352dabfd8d97"
      },
      "id": "VNNDIP5AR58A",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bad-teaching-unlearning2'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 19 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (19/19), 1.28 MiB | 6.35 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/bad-teaching-unlearning2')"
      ],
      "metadata": {
        "id": "Qq4SWBe5SGM3"
      },
      "id": "Qq4SWBe5SGM3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "djAES1sjJt3Q"
      },
      "id": "djAES1sjJt3Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '16wHH5rVTkb4sEJ3p-ArUiZ1Nd40uqG6q'\n",
        "destination = '/content/bad-teaching-unlearning2/mini child dataset.zip'\n",
        "gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', destination, quiet=False)"
      ],
      "metadata": {
        "id": "hCBKnvTvJqVn"
      },
      "id": "hCBKnvTvJqVn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "1zS0gMDzSLys"
      },
      "id": "1zS0gMDzSLys",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/bad-teaching-unlearning2/mini child dataset.zip'\n",
        "extract_dir = '/content/bad-teaching-unlearning2/'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "BAmvMDK2SU8i"
      },
      "id": "BAmvMDK2SU8i",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vzi0XhzAIBOp"
      },
      "id": "Vzi0XhzAIBOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b09aca22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b09aca22",
        "outputId": "1ed48545-7edd-467f-adbf-5e6d812124b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown"
      ],
      "metadata": {
        "id": "qk96P75SQzpp"
      },
      "id": "qk96P75SQzpp",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '16wHH5rVTkb4sEJ3p-ArUiZ1Nd40uqG6q'\n",
        "destination = '/content/mini child dataset.zip'\n",
        "gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', destination, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "uU6Hh8X0I2es",
        "outputId": "e64bcb42-5b5b-4a8d-9536-5cba28c83624"
      },
      "id": "uU6Hh8X0I2es",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=16wHH5rVTkb4sEJ3p-ArUiZ1Nd40uqG6q\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=16wHH5rVTkb4sEJ3p-ArUiZ1Nd40uqG6q&confirm=t&uuid=1b297637-5671-4f8a-b397-0fc62e92e0f6\n",
            "To: /content/mini child dataset.zip\n",
            "100%|██████████| 73.8M/73.8M [00:02<00:00, 25.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mini child dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "488660ae",
      "metadata": {
        "id": "488660ae"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "52536328",
      "metadata": {
        "id": "52536328"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to the desired size (e.g., 224x224 for ResNet)\n",
        "    transforms.ToTensor(),          # Convert image to PyTorch tensor\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet values\n",
        "    transforms.Normalize(mean=[0.4581, 0.4581, 0.4581], std=[0.2589, 0.2589, 0.2589])  # Values for this dataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ae395229",
      "metadata": {
        "id": "ae395229"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = ImageFolder(root='/content/bad-teaching-unlearning2/mini child dataset', transform=transform)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0e63937e",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e63937e",
        "outputId": "4607d983-e40b-4d8b-fa5e-eff0859d3906"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 80\n",
              "    Root location: /content/bad-teaching-unlearning2/mini child dataset\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.4581, 0.4581, 0.4581], std=[0.2589, 0.2589, 0.2589])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6115b86c",
      "metadata": {
        "id": "6115b86c"
      },
      "outputs": [],
      "source": [
        "#finding mean and std for images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272f3b2c",
      "metadata": {
        "id": "272f3b2c"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(root='mini child dataset', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5508134c",
      "metadata": {
        "id": "5508134c"
      },
      "outputs": [],
      "source": [
        "mean = torch.zeros(3)\n",
        "std = torch.zeros(3)\n",
        "n_samples = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39d1f36",
      "metadata": {
        "id": "d39d1f36"
      },
      "outputs": [],
      "source": [
        "for images, _ in dataloader:\n",
        "    # Resize images to [N, 3, H, W]\n",
        "    images = images.view(images.size(0), images.size(1), -1)\n",
        "    # Update the sum and sum of squares\n",
        "    mean += images.mean(2).sum(0)\n",
        "    std += images.std(2).sum(0)\n",
        "    n_samples += images.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0ac477",
      "metadata": {
        "id": "8a0ac477"
      },
      "outputs": [],
      "source": [
        "mean /= n_samples\n",
        "std /= n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d77a81",
      "metadata": {
        "id": "00d77a81"
      },
      "outputs": [],
      "source": [
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b67372b",
      "metadata": {
        "id": "0b67372b"
      },
      "outputs": [],
      "source": [
        "#end of finding mean and std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fd157e1c",
      "metadata": {
        "id": "fd157e1c"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and test sets (e.g., 80% training, 20% testing)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "train_ds, valid_ds = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i[1] for i in list(valid_ds)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzp50wXSVo_n",
        "outputId": "202961db-0ff1-484d-e1de-6b5eb457c1a7"
      },
      "id": "fzp50wXSVo_n",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "018919eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "018919eb",
        "outputId": "daff7674-29f9-4d5b-b162-1e73ee6640ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(list(train_ds)[0][0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "776d0e24",
      "metadata": {
        "id": "776d0e24"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(valid_ds, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1532a6d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1532a6d1",
        "outputId": "747aec79-a463-4fca-b8b0-71aaeabdfae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 80\n",
            "Training images: 64\n",
            "Testing images: 16\n"
          ]
        }
      ],
      "source": [
        "# Verify the dataset structure and labels\n",
        "print(f'Total images: {len(dataset)}')\n",
        "print(f'Training images: {len(train_ds)}')\n",
        "print(f'Testing images: {len(valid_ds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6c2ddf56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c2ddf56",
        "outputId": "bb9893f8-85b9-4156-ebf8-f0f3fec0f3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 224, 224])\n",
            "tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "for images, labels in test_loader:\n",
        "    print(images.shape)  # Batch size x Channels x Height x Width\n",
        "    print(labels)        # Labels for the batch\n",
        "    break  # Just checking one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb59cb9",
      "metadata": {
        "id": "dfb59cb9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e64c43",
      "metadata": {
        "id": "04e64c43"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e417fd26",
      "metadata": {
        "id": "e417fd26"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataset import *\n",
        "from model import ResNet18\n",
        "from unlearn import *\n",
        "from metrics import UnLearningScore\n",
        "from utils import *\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e606b811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e606b811",
        "outputId": "a04733fd-722c-4727-aee5-0a337e219352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "#train_ds = CustomCIFAR100(root='.', train=True,download=True, transform=transform_train)\n",
        "#valid_ds = CustomCIFAR100(root='.', train=False,download=True, transform=transform_train)\n",
        "\n",
        "batch_size = 256\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=32, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size, num_workers=32, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ca7f45e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ca7f45e9",
        "outputId": "7ce3efdd-3016-4d8f-c869-bb558f0dbe58"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a0be1c17c5b0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "35d8927b",
      "metadata": {
        "id": "35d8927b"
      },
      "outputs": [],
      "source": [
        "\"\"\"num_classes = 100\n",
        "classwise_train = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_train[i] = []\n",
        "\n",
        "for img, label, clabel in train_ds:\n",
        "    classwise_train[label].append((img, label, clabel))\n",
        "\n",
        "classwise_test = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_test[i] = []\n",
        "\n",
        "for img, label, clabel in valid_ds:\n",
        "    classwise_test[label].append((img, label, clabel))\"\"\"\n",
        "\n",
        "num_classes = 2\n",
        "classwise_train = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_train[i] = []\n",
        "\n",
        "for img, label in train_ds:\n",
        "    classwise_train[label].append((img, label))\n",
        "\n",
        "classwise_test = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_test[i] = []\n",
        "\n",
        "for img, label in valid_ds:\n",
        "    classwise_test[label].append((img, label))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = 'cpu'\n",
        "#import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "device = xm.xla_device()"
      ],
      "metadata": {
        "id": "ZPE9o-IOlM1v"
      },
      "id": "ZPE9o-IOlM1v",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d97228e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97228e9",
        "outputId": "6560dac6-b004-4e88-c5aa-4acc583d026e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00100, train_loss: 0.7252, val_loss: 1.0842, val_acc: 56.2500\n",
            "Epoch [1], last_lr: 0.00100, train_loss: 1.4301, val_loss: 1.4721, val_acc: 62.5000\n",
            "Epoch [2], last_lr: 0.00100, train_loss: 0.0310, val_loss: 1.9657, val_acc: 56.2500\n",
            "Epoch [3], last_lr: 0.00100, train_loss: 0.0369, val_loss: 1.3946, val_acc: 62.5000\n",
            "Epoch [4], last_lr: 0.00100, train_loss: 0.0860, val_loss: 2.9604, val_acc: 62.5000\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "#device = 'cuda'\n",
        "model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
        "epochs = 5\n",
        "history = fit_one_cycle(epochs, model, train_dl, valid_dl, device = device)\n",
        "torch.save(model.state_dict(), \"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f162fe",
      "metadata": {
        "id": "60f162fe"
      },
      "outputs": [],
      "source": [
        "print (\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "41b694e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41b694e9",
        "outputId": "6e9500f8-8275-4573-fcc8-cd97c9ea38d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# load the trained model\n",
        "#device = 'cuda'\n",
        "model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
        "model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21037453",
      "metadata": {
        "id": "21037453"
      },
      "source": [
        "# Forgetting Rocket\n",
        "The Rocket is class 69 in CIFAR100 and belongs to Super Class 19 (Vehicles) in CIFAR Super 20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7b58c474",
      "metadata": {
        "id": "7b58c474"
      },
      "outputs": [],
      "source": [
        "# Getting the forget and retain validation data\n",
        "\"\"\"forget_valid = []\n",
        "forget_classes = [0]\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label, clabel in classwise_test[cls]:\n",
        "            forget_valid.append((img, label, clabel))\n",
        "\n",
        "retain_valid = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label, clabel in classwise_test[cls]:\n",
        "            retain_valid.append((img, label, clabel))\n",
        "\n",
        "forget_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label, clabel in classwise_train[cls]:\n",
        "            forget_train.append((img, label, clabel))\n",
        "\n",
        "retain_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label, clabel in classwise_train[cls]:\n",
        "            retain_train.append((img, label, clabel))\"\"\"\n",
        "forget_valid = []\n",
        "forget_classes = [0]\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label in classwise_test[cls]:\n",
        "            forget_valid.append((img, label))\n",
        "\n",
        "retain_valid = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label in classwise_test[cls]:\n",
        "            retain_valid.append((img, label))\n",
        "\n",
        "forget_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            forget_train.append((img, label))\n",
        "\n",
        "retain_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            retain_train.append((img, label))\n",
        "\n",
        "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=32, pin_memory=True)\n",
        "\n",
        "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=32, pin_memory=True)\n",
        "\n",
        "forget_train_dl = DataLoader(forget_train, batch_size, num_workers=32, pin_memory=True)\n",
        "retain_train_dl = DataLoader(retain_train, batch_size, num_workers=32, pin_memory=True, shuffle = True)\n",
        "import random\n",
        "retain_train_subset = random.sample(retain_train, int(0.3*len(retain_train)))\n",
        "retain_train_subset_dl = DataLoader(retain_train_subset, batch_size, num_workers=32, pin_memory=True, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in forget_valid:\n",
        "    ax, ay = i"
      ],
      "metadata": {
        "id": "CTrJyxfQW-Cx"
      },
      "id": "CTrJyxfQW-Cx",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "03937bfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03937bfe",
        "outputId": "72bac6cb-46e3-4f66-dc2c-02d7b37ba7ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 4.772350788116455, 'Acc': 44.4444465637207}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Performance of Fully trained model on retain set\n",
        "evaluate(model, retain_valid_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bd36874a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd36874a",
        "outputId": "27499df4-cf36-4e48-e098-a47186b8e7ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.6307050585746765, 'Acc': 85.71428680419922}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Performance of Fully trained model on forget set\n",
        "evaluate(model, forget_valid_dl, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f511d908",
      "metadata": {
        "id": "f511d908"
      },
      "source": [
        "## Retrain the model from Scratch\n",
        "Create Retrained Model (Gold model). This is the model trained from scratch without forget data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5e6b6f86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6b6f86",
        "outputId": "bd4f2afa-20ff-43dc-d2d5-ce978b403a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00100, train_loss: 1.4336, val_loss: 0.0013, val_acc: 100.0000\n",
            "Epoch [1], last_lr: 0.00100, train_loss: 0.0008, val_loss: 0.0000, val_acc: 100.0000\n",
            "Epoch [2], last_lr: 0.00100, train_loss: 0.0000, val_loss: 0.0000, val_acc: 100.0000\n",
            "Epoch [3], last_lr: 0.00100, train_loss: 0.0000, val_loss: 0.0000, val_acc: 100.0000\n",
            "Epoch [4], last_lr: 0.00100, train_loss: 0.0000, val_loss: 0.0000, val_acc: 100.0000\n"
          ]
        }
      ],
      "source": [
        "#device = 'cuda'\n",
        "gold_model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
        "epochs = 5\n",
        "history = fit_one_cycle(epochs, gold_model, retain_train_dl, retain_valid_dl, device = device)\n",
        "torch.save(gold_model.state_dict(), \"ResNET18_ChildNonChild_Pretrained_Gold_Class0_5_Epochs.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3c55d80d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c55d80d",
        "outputId": "4e8fd2f2-3335-4f40-e88e-6ec275b3dabf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#device = 'cuda'\n",
        "gold_model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
        "gold_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_Gold_Class0_5_Epochs.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "00cd59f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00cd59f5",
        "outputId": "6e24494d-04c6-4611-d823-ac02f80b39b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 33.24491882324219, 'Acc': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# evaluate gold model on forget set\n",
        "evaluate(gold_model, forget_valid_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1f9deb20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f9deb20",
        "outputId": "084f3cfe-54e7-409d-ed4e-6e2f9b5e6b99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.0, 'Acc': 100.0}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# evaluate gold model on retain set\n",
        "evaluate(gold_model, retain_valid_dl, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad52614d",
      "metadata": {
        "id": "ad52614d"
      },
      "source": [
        "## UnLearning via proposed method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "397472c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397472c2",
        "outputId": "d07243c7-dbe0-4821-f227-42523d3d3ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Unlearning Loss 1.3698110580444336\n"
          ]
        }
      ],
      "source": [
        "#device = 'cuda'\n",
        "unlearning_teacher = ResNet18(num_classes = 2, pretrained = False).to(device).eval()\n",
        "student_model = ResNet18(num_classes = 2, pretrained = False).to(device)\n",
        "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))\n",
        "model = model.eval()\n",
        "\n",
        "KL_temperature = 1\n",
        "\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr = 0.0001)\n",
        "\n",
        "blindspot_unlearner(model = student_model, unlearning_teacher = unlearning_teacher, full_trained_teacher = model,\n",
        "          retain_data = retain_train_subset, forget_data = forget_train, epochs = 1, optimizer = optimizer, lr = 0.0001,\n",
        "          batch_size = 256, num_workers = 32, device = device, KL_temperature = KL_temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "26bdd978",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26bdd978",
        "outputId": "43f77ef3-47aa-46d3-f02b-caf9e86aca2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 1.0596378530181028e-07, 'Acc': 100.0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# performance of unlearned model on forget set\n",
        "evaluate(student_model, forget_valid_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "10464482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10464482",
        "outputId": "5708531e-5e5d-4542-c1f0-8e202480265a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Loss': 0.1192394495010376, 'Acc': 85.71428680419922}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# performance of unlearned model on retain set\n",
        "evaluate(student_model, retain_valid_dl, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22adfc9",
      "metadata": {
        "id": "f22adfc9"
      },
      "source": [
        "### Measure ZRF (Unlearning Score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b5293709",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5293709",
        "outputId": "7a06f7d1-a53f-432d-f1f9-318a1cd47c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Initial Score: -0.15881824493408203\n",
            "2\n",
            "Our Score: 0.0536617636680603\n",
            "2\n",
            "Gold Score: -1.2329230308532715\n",
            "2\n",
            "JS Div: 6.1844916343688965\n"
          ]
        }
      ],
      "source": [
        "print(\"Initial Score: {}\".format(UnLearningScore(model, unlearning_teacher, forget_valid_dl, 256, device)))\n",
        "print(\"Our Score: {}\".format(UnLearningScore(student_model, unlearning_teacher, forget_valid_dl, 256, device)))\n",
        "print(\"Gold Score: {}\".format(UnLearningScore(gold_model, unlearning_teacher, forget_valid_dl, 256, device)))\n",
        "print(\"JS Div: {}\".format(1-UnLearningScore(gold_model, student_model, forget_valid_dl, 256, device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86abfa01",
      "metadata": {
        "id": "86abfa01"
      },
      "source": [
        "## Unlearning using Amnesiac unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1e0e6a09",
      "metadata": {
        "id": "1e0e6a09"
      },
      "outputs": [],
      "source": [
        "unlearninglabels = list(range(2))\n",
        "unlearninglabels.remove(0)\n",
        "unlearning_train_set = []\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            unlearning_train_set.append((img, random.choice(unlearninglabels)))\n",
        "\n",
        "\n",
        "\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            unlearning_train_set.append((img, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2f2cd7b2",
      "metadata": {
        "id": "2f2cd7b2"
      },
      "outputs": [],
      "source": [
        "unlearning_train_set_dl = DataLoader(unlearning_train_set, batch_size, num_workers = 32, pin_memory = True, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3e8b3ec7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e8b3ec7",
        "outputId": "1e9cd9f8-c710-4438-9232-abc2bd0cc76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], last_lr: 0.00010, train_loss: 7.9702, val_loss: 0.0850, val_acc: 100.0000\n",
            "Epoch [1], last_lr: 0.00010, train_loss: 7.0818, val_loss: 0.0736, val_acc: 100.0000\n",
            "Epoch [2], last_lr: 0.00010, train_loss: 6.3866, val_loss: 0.2006, val_acc: 85.7143\n"
          ]
        }
      ],
      "source": [
        "#device = 'cuda'\n",
        "student_model = ResNet18(num_classes = 2, pretrained = True).to(device)\n",
        "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))\n",
        "epochs = 3\n",
        "\n",
        "history = fit_one_unlearning_cycle(epochs, student_model, unlearning_train_set_dl, retain_valid_dl, device = device, lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "47012a75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47012a75",
        "outputId": "d0a57a79-aefa-4353-886e-17d6e9911c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forget Performance: {'Loss': 2.7285418582323473e-06, 'Acc': 100.0}\n",
            "Retain Performance: {'Loss': 0.20064125955104828, 'Acc': 85.71428680419922}\n"
          ]
        }
      ],
      "source": [
        "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
        "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ddfcfd6",
      "metadata": {
        "id": "8ddfcfd6"
      },
      "source": [
        "## Unlearning using UNSIR (Class 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d13dc46f",
      "metadata": {
        "id": "d13dc46f"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "classwise_train = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_train[i] = []\n",
        "\n",
        "for img, label in train_ds:\n",
        "    classwise_train[label].append((img, label))\n",
        "\n",
        "classwise_test = {}\n",
        "for i in range(num_classes):\n",
        "    classwise_test[i] = []\n",
        "\n",
        "for img, label in valid_ds:\n",
        "    classwise_test[label].append((img, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "abff2da1",
      "metadata": {
        "id": "abff2da1"
      },
      "outputs": [],
      "source": [
        "# Getting the forget and retain validation data\n",
        "forget_valid = []\n",
        "forget_classes = [0]\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label in classwise_test[cls]:\n",
        "            forget_valid.append((img, label))\n",
        "\n",
        "retain_valid = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label in classwise_test[cls]:\n",
        "            retain_valid.append((img, label))\n",
        "\n",
        "forget_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            forget_train.append((img, label))\n",
        "\n",
        "retain_train = []\n",
        "for cls in range(num_classes):\n",
        "    if cls not in forget_classes:\n",
        "        for img, label in classwise_train[cls]:\n",
        "            retain_train.append((img, label))\n",
        "\n",
        "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=32, pin_memory=True)\n",
        "\n",
        "retain_valid_dl = DataLoader(retain_valid, batch_size, num_workers=32, pin_memory=True)\n",
        "\n",
        "forget_train_dl = DataLoader(forget_train, batch_size, num_workers=32, pin_memory=True)\n",
        "retain_train_dl = DataLoader(retain_train, batch_size, num_workers=32, pin_memory=True, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "80d3a0af",
      "metadata": {
        "id": "80d3a0af"
      },
      "outputs": [],
      "source": [
        "#collect some samples from each class\n",
        "#num_samples = 500\n",
        "num_samples = 20\n",
        "retain_samples = []\n",
        "for i in range(num_classes):\n",
        "    if i not in forget_classes:\n",
        "        retain_samples += classwise_train[i][:num_samples]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e273c408",
      "metadata": {
        "id": "e273c408"
      },
      "outputs": [],
      "source": [
        "noise_batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "07307a30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07307a30",
        "outputId": "54fc7c21-8e0c-4796-84d5-4bbc62ca260c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#device = 'cuda'\n",
        "student_model = ResNet18(num_classes = 2, pretrained = False).to(device)\n",
        "student_model.load_state_dict(torch.load(\"ResNET18_ChildNonChild_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "035388b6",
      "metadata": {
        "id": "035388b6"
      },
      "outputs": [],
      "source": [
        "noise = UNSIR_noise(batch_size, 3, 224, 224).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "0e1a6d67",
      "metadata": {
        "id": "0e1a6d67"
      },
      "outputs": [],
      "source": [
        "forget_class_label = 0\n",
        "#num_epochs = 250\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3367b5e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3367b5e0",
        "outputId": "eb981595-42b0-4aca-90cc-91d03c888c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 15050.14453125\n",
            "Loss: 6418.26904296875\n",
            "Loss: 2584.432861328125\n",
            "Loss: 1118.4263916015625\n"
          ]
        }
      ],
      "source": [
        "noise =  UNSIR_noise_train(noise, student_model, forget_class_label, num_epochs,\\\n",
        "                           noise_batch_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "1c6babe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "1c6babe7",
        "outputId": "1c91972f-850b-4f6f-f093-d478c8c0a733"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-e59044226dd1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m noisy_loader = UNSIR_create_noisy_loader(noise, forget_class_label\\\n\u001b[0m\u001b[1;32m      2\u001b[0m                                          , retain_samples, batch_size, device=device)\n",
            "\u001b[0;32m/content/bad-teaching-unlearning2/unlearn.py\u001b[0m in \u001b[0;36mUNSIR_create_noisy_loader\u001b[0;34m(noise, forget_class_label, retain_samples, batch_size, num_noise_batches, device)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mother_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][2]),\\\n\u001b[0m\u001b[1;32m    130\u001b[0m                             torch.tensor(retain_samples[i][2])))\n\u001b[1;32m    131\u001b[0m     \u001b[0mnoisy_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mother_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "noisy_loader = UNSIR_create_noisy_loader(noise, forget_class_label\\\n",
        "                                         , retain_samples, batch_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7942492",
      "metadata": {
        "id": "f7942492"
      },
      "outputs": [],
      "source": [
        "#impair step\n",
        "epochs = 1\n",
        "history = fit_one_unlearning_cycle(epochs, student_model, noisy_loader, retain_valid_dl, device = device, lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0ba1a6",
      "metadata": {
        "id": "9a0ba1a6"
      },
      "outputs": [],
      "source": [
        "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
        "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa107882",
      "metadata": {
        "id": "aa107882"
      },
      "outputs": [],
      "source": [
        "#repair step\n",
        "other_samples = []\n",
        "for i in range(len(retain_samples)):\n",
        "    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][2]),\n",
        "                            torch.tensor(retain_samples[i][2])))\n",
        "\n",
        "heal_loader = torch.utils.data.DataLoader(other_samples, batch_size=batch_size, shuffle = True)\n",
        "epochs = 1\n",
        "history = fit_one_unlearning_cycle(epochs, student_model, heal_loader, retain_valid_dl, device = device, lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301da275",
      "metadata": {
        "id": "301da275"
      },
      "outputs": [],
      "source": [
        "print(\"Forget Performance: {}\".format(evaluate(student_model, forget_valid_dl, device)))\n",
        "print(\"Retain Performance: {}\".format(evaluate(student_model, retain_valid_dl, device)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0118f1d6",
      "metadata": {
        "id": "0118f1d6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}